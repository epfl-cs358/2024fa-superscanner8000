\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{tkz-euclide}
\usepackage{ragged2e}
\usepackage{hyperref}
\usepackage{float}
\usepackage{tikz}
\usepackage{float}
\usepackage{multirow}
\usepackage{biblatex}
\usepackage[graphicx]{realboxes}
\addbibresource{refs.bib}

\pagestyle{fancy}
\geometry{top=3cm, bottom=2.5cm, left=3.5cm, right=3.5cm}
\rhead{CS-358}
\lhead{\leftmark}
\fancyfoot[R]{\leftmark}
\fancyfoot[C]{}
\fancyfoot[L]{Page \thepage}
\renewcommand{\footrulewidth}{1pt}
\usepackage{multicol}
\title{CS-358: Individual Project Proposal}
\author{Noa Ette - \\Mateo Tiedra - 356525\\Kevan Lam - \\Louis Larcher - \\Ugo -}
\date{\today}

\begin{document}


\maketitle
\vspace{45mm}
\tableofcontents
\newpage
\section{Project Description: Autonomous 3d Object Scanner}

The core of this project idea is to make a mobile robot capable of identifying the object of interest and taking pictures of it from all (possible) angles. 
This would be paired with a desktop application that would receive the images and apply the user selected 3d reconstruction algorithm.\\


From this description we can identify several key components the project needs: \begin{enumerate}
    \item \texttt{The Robot}:
    \begin{description}
            \item[1.1] Navigate and plan routes around object.
            \item[1.2] Segment view and recognize object of interest.
            \item[1.3] Translate camera on z axis whilst tracking object of interest.
    \end{description}
    \item \texttt{The Desktop Application}:
    \begin{description}
        \item[2.1] User can choose object of interest.
        \item[2.2] Process images sent by robot using 3d reconstruction algorithms (NeRF \cite{mildenhall2020nerf}, 3DGS \cite{kerbl3Dgaussians}, Multi-view stereo)
    \end{description}
\end{enumerate}

Nowadays, one does not need specialised high end equipment in order to 3d scan objects. Most of us already have the sufficient equipment needed, a smartphone, given that it has a functioning camera and the adequate software. \\
For this project we will not be using a smartphone as it gives the robot higher usefulness and does not drastically increase complexity to have an integrated camera. 

In order to move the camera we will use an arm with two segments each powered by a stepper motor (like the Pixar lamp) fixed on top of the robot and oriented perpendicular to the wheels. In addition, the camera will be fixed to the arm using two servos offering roll and pitch control.


Most currently existing 3d Object scanners are catered to small objects \cite{desktop3dscanner}, rotating the object and photographing it from a fixed camera. We decided to take a different approach with the goal to give more flexibility while keeping the complexity as low as possible.


\newpage
\section{Related Projects}
We have looked at various related projects whilst trying to figure out how to design ours in the best possible manner.

We figured a mostly square base with two motors placed on diagonal wheels would be the most practical while being resource efficient and simple. This setup allows the "car" part of the robot to spin on itself, removing the need of having the arm holding the camera spin. This kind of movement is principally inspired by tanks, excavators and other tracked vehicles, except the two wheels on each side are independent instead of linked by a track.

The arm on the other hand takes inspiration from the many existing robotic or industrial arms existing. More particularly, we found this design \cite{cameraArm} which achieves a similar purpose as ours. Moving the motor for the second joint to the base is a key element of the design since it allows to have weaker motors and an overall lower center of gravity.

Unfortunately we have been unsuccessful in finding a project where a robot tracks an object, rotating around it. This poses a particular computer vision challenge as the robot needs to be able to recognise the object from completely distinct angles. Thanks to the fact that the robot will be navigating using video from an ESP32-CAM on the front of the robot, basic object tracking like those in opencv will most likely be sufficient.




\section{User Stories}

The final product of this project is something that could be useful to many people from different horizons. \\
In one case, one could imagine a real estate agent, wanting to provide virtual visits of a home he is selling. Instead of having to contact a freelance 3D artist to remodel the home, probably costing thousands, they would be able to simply 3d scan the area using the robot and software made in this project, saving plenty of time and money. Some companies have already ventured into real-estate specific 3d scanning \cite{matterport}. \\
Another imaginable use case is for professional 3d artists wanting to use realistic large objects in their 3d scenes. The conventional way to scan these objects would be to manually take pictures of them. Something that is very time consuming and sometimes requires particular gymnastics skills.
I personally have a little bit of experience with manually 3d scanning objects and can personally attest that, depending on the object, it can take a frustratingly long amount of time.

It could be an interesting demonstration for the EPFL Open House as it demonstrates the link between 3d art and computer science by leveraging an intelligent robot to optimise the workload of different career paths.

\section{Long term view}

Given a long term viewpoint, we could easily imagine different form factors being based on this project being developed for many different use cases. 

At a much larger scale, terrestrial and aerial 3d scanning robots could be used to map entire city's. Re-creating what would take thousands if not millions of man hours. This data could be used to train autonomous vehicles on real city's though simulation or for many other projects.

At a smaller scale, this technology could be redesigned on an aquatic form factor in order to map ocean floors and areas inaccessible by humans.

\newpage
\section{Physical description}

The robot takes the form of a square "car" with four wheels, 2 of which are powered by brushed motors. An ESP-32 cam on the front of the car allows to make decisions on the movement of the car regarding it environment, this will be further detailed in the next section. On top of the car lies an arm with two joints, each powered by a stepper motor. The arm is facing perpendicular to the direction of travel and on top of it is mounted a second esp-32 cam with an upgraded OV5640 camera. This camera contributes to the navigation but most importantly takes pictures of the object of interest from different angles and at different heights for later reconstruction. The camera is fixed to the arm using two servos, one controlling the pitch and the other the roll.

Regarding the control of all these motors, both esp-32 cam being quite limited in terms of I/O, we have a third micro-controller to handle them.

In terms of power, our thing will work on LiPo batteries, with a battery management board and voltage converters ensuring adequate power to all parts.

For further details on the design, please refer to the 3D files provided with this document.

\section{Software description}

The Superscanner8000 software run on a computer connected to the robot through Wi-Fi. The program allows users to select an object within the cameraâ€™s field of view and adjust a parameter that specifies the level of precision needed, determining the number of photos the robot will capture. Once selected, the software guides the robot to navigate around the object, capturing images from various angles and distances. After gathering a sufficient number of images, the software processes them to generate a 3D model of the object, which can then be exported.

To enable the user to select an object for scanning, the software displays the live video feed from the robot camera on the screen, showing various objects in view. The user can click directly on the object of interest, which will then be detected and highlighted using Meta's open-source model, SAM 2.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{images/sam2-example.png}
    \caption{Example of SAM 2's image segmentation}
    \label{fig:sam2-example}
\end{figure}

After the object is selected, the software directs the robot to move in a circular path around it. The robot moves in one direction while simultaneously using object segmentation to keep the object centered in the camera's field of view, rotating its entire body to maintain this alignment. Once it has completed a portion of the path, the software halts the robot, allowing it to capture images from different angles by adjusting the arm and raising or lowering the camera and the starts it again to move to the next position. This process is repeated until the robot has completed a full circle around the object. The user can stop the process at any time with a button on the software interface.

The images are transmitted from the robot to the computer in real time as the device moves and captures additional photos. Once the robot completes its data-gathering walk around the object and all images have been uploaded to the computer, the system initiates the 3D object conversion process using 3D reconstruction algorithms such as 3DGS \cite{kerbl3Dgaussians} and NeRF \cite{mildenhall2020nerf}.

\newpage
\section{Bill of materials}

\begin{center}
\Rotatebox{90}{%
\begin{tabular}{ ||c|c|c|c|c|c|| } 

\hline
Category & Type & Name & Site & Amount & Price \\
\hline
\hline
\multirow{4}{5em}{Actuators} 
& brushed motor & Chihai CHF-GM37-550ABHL & [In stock] & 2 & 25 \\ 
& brushed driver & L298N & [In stock] & 2 & 5\\
& stepper + driver & 17HS4401 + A4988 & [In stock] & 2 & 15 \\
& servo & SG90 & [In stock] & 2 & 3 \\
\hline
\hline
\multirow{4}{5em}{Controllers} 
& controller + camera & AIThinker esp32-cam & [In stock] & 2 & 4\\ 
& camera & OV5640 & \href{https://www.digikey.ch/fr/products/detail/seeed-technology-co-ltd/114993115/21277047}{digikey.ch} & 1 & 10.89\\ 
& microcontroller & ESP32-S2-DEVKITM-1U-N4R2 & \href{https://www.digikey.ch/fr/products/detail/espressif-systems/ESP32-S2-DEVKITM-1U-N4R2/16688756}{digikey.ch} & 1 & 7.27\\
& UART to USB & FTDI USB-to-serial & [In stock] & 1 & 2\\
\hline
\hline
\multirow{7}{5em}{Power}
& battery & Absima 11.1 V 6000 mAh 3S 50 C & \href{https://www.conrad.ch/fr/p/absima-pack-de-batterie-lipo-11-1-v-6000-mah-nombre-de-cellules-3-50-c-stick-xt90-3322657.html}{conrad.ch} & 1 & 51.95 \\
& BMS & 3S 12V 40A BMS & \href{https://www.elektronik-kaufen.ch/products/bms-3s-40a?variant=41643639701680&currency=CHF}{elektronik-kaufen.ch} & 1 & 5.5 \\
& heatsink & aluminum sheet & [In SPOT shop] & 1 & 10 \\
& battery plug male & XT90-S male plug & \href{https://www.conrad.ch/fr/p/reely-re-6702312-fiche-male-pour-batterie-xt90-s-dore-e-1-pc-s-2234104.html}{conrad.ch} & 2 & 1.9 \\
& battery plug female & XT90-S female plug & \href{https://www.conrad.ch/fr/p/reely-re-7471836-prise-femelle-pour-batterie-xt90-dore-e-1-pc-s-2490612.html}{conrad.ch} & 1 & 1.6 \\
& load balance plug & JST XH2.54 3p 20cm & \href{https://www.bastelgarage.ch/cable-de-connexion-jst-xh2-54-3p-20cm}{bastelgarage.ch} & 1 & 0.6 \\
& voltage converter & LM2596 & [In stock] & 2 & 3 \\
\hline
\hline
\multicolumn{5}{|r|}{total cost} & 203.61\\
\hline
\hline
\end{tabular}
}%
\end{center}

\newpage
\printbibliography

\end{document}
